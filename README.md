# sme5qyx_DS5111su24_lab_01

### tokenizer_functions.py

* 'clean_text(input_text)'
  - This function removes punctuation from the input string and converts all characters to lowercase. It is designed to standardize text for easier processing.

* 'tokenize(input_text)'
  - This function splits the cleaned input string into a list of individual words (tokens). It helps in breaking down text into manageable parts for analysis.

* count_words(input_text)
  - This function counts the frequency of each word in the input string and returns a dictionary with words as keys and their counts as values. It provides a straightforward way to analyze word occurrences in the text.
 
### Example code for clean_text(input_text)

* input_text = "My name is Sarah and this is my last semester!"
* cleaned_text = clean_text(input_text)
* print(cleaned_text)
  * output:
    - my name is sarah and this is my last semester 

 
